from flask import Flask, render_template, request, jsonify
import os, re, random
import requests
from dotenv import load_dotenv
import json
from datetime import datetime

load_dotenv()
YOUTUBE_API_KEY = os.getenv("YOUTUBE_API_KEY")

app = Flask(__name__)

# =============================
# Keywords (M4 minimal)
# =============================
POSITIVE_KEYWORDS_KO = [
    "ì¢‹ë‹¤","ì¢‹ì•„ìš”","ìµœê³ ","ì¬ë°Œ","ì¬ë¯¸","ê°ë™","ëŒ€ë°•","í–‰ë³µ","íë§","ì‘ì›","ì‚¬ë‘","ë©‹ì§€","ì§±",
    "ê¿€ì¼","ì¡´ì¼","ê°œê¿€","ë ˆì „ë“œ","ê°“","ì°¢ì—ˆ","ë¯¸ì³¤ë‹¤","ë¯¸ì³¤ë„¤","ê°œì˜","ì˜í•œë‹¤","ìµœê³ ë‹¤","ì‚¬ë‘í•´",
    "ë„ˆë¬´ ì¢‹","ë„ˆë¬´ ì¬ë°Œ","ì›ƒê¸°ë‹¤","ê°ë™ì ","ê°ì‚¬í•©ë‹ˆë‹¤"
]
NEGATIVE_KEYWORDS_KO = ["ë³„ë¡œ","ì‹«ë‹¤","ìµœì•…","ë¶ˆí¸","ì‹¤ë§","ì§œì¦","í™”ë‚˜","ë…¸ì¼","êµ¬ë¦¬","ë§","ìš•","í—¬","ë‹µë‹µ","ì£¼ì‘","ì“°ë ˆê¸°","ê±°í’ˆíŒ€","ë³‘ë§›","ê°œëª»","ëª»í•œë‹¤","ë³„ë¡œë‹¤","ì‹«ì–´","ë„ˆë¬´ ë³„ë¡œ","ì¬ë¯¸ì—†ë‹¤","ì§€ë£¨í•˜ë‹¤","ê°ë™ ì—†ë‹¤","ë˜¥ë¨¹ì–´ë¼", "ë‚´ë³´ë‚´", "ì³ë°œë¦¬","ëª»í•˜"]

POSITIVE_KEYWORDS_EN = ["good","great","awesome","amazing","love","best","fun","cool","perfect","thanks","helpful"]
NEGATIVE_KEYWORDS_EN = ["bad","worst","hate","terrible","awful","boring","trash","annoying","dislike","cringe","scam"]

POSITIVE_KEYWORDS_JA = ["æœ€é«˜","å¥½ã","ã„ã„","è‰¯ã„","é¢ç™½","æ„Ÿå‹•","ã™ã”ã„","ã‚ã‚ŠãŒã¨ã†","å¯æ„›ã„","ç¥"]
NEGATIVE_KEYWORDS_JA = ["å«Œã„","æœ€æ‚ª","ã¤ã¾ã‚‰","å¾®å¦™","ã²ã©ã„","ã‚´ãƒŸ","ã†ã–ã„","ç„¡ç†"]

POSITIVE_KEYWORDS_ZH = ["å¥½","å¾ˆå¥½","å¤ªæ£’","å–œæ¬¢","çˆ±","ç²¾å½©","æ„ŸåŠ¨","å‰å®³","è°¢è°¢","å¯çˆ±"]
NEGATIVE_KEYWORDS_ZH = ["å·®","å¾ˆå·®","è®¨åŒ","æœ€å·®","æ— èŠ","åƒåœ¾","æ¶å¿ƒ","ç³Ÿç³•","å¤±æœ›"]

KEYWORDS = {
    "ko": (POSITIVE_KEYWORDS_KO, NEGATIVE_KEYWORDS_KO),
    "en": (POSITIVE_KEYWORDS_EN, NEGATIVE_KEYWORDS_EN),
    "ja": (POSITIVE_KEYWORDS_JA, NEGATIVE_KEYWORDS_JA),
    "zh": (POSITIVE_KEYWORDS_ZH, NEGATIVE_KEYWORDS_ZH),
}

POSITIVE_EMOJIS = ["â¤ï¸","ğŸ’•","ğŸ’–","ğŸ”¥","ğŸ‘","ğŸ‘","ğŸ˜‚","ğŸ¤£","ğŸ¥¹"]
NEGATIVE_EMOJIS = ["ğŸ¤®","ğŸ¤¢","ğŸ˜¡","ğŸ¤¬","ğŸ‘",";"]


ALLOWED_MAX = {50, 100, 200}
ALLOWED_SORT = {"latest", "likes"}
ALLOWED_LANG = {"auto", "ko", "en", "ja", "zh"}
MIN_LEN = 3

# =============================
# Routes
# =============================
@app.get("/")
def home():
    return render_template("index.html")

@app.get("/test")
def test_api():
    return jsonify({"message": "server is working"})

@app.get("/routes")
def routes():
    return jsonify(sorted([str(r) for r in app.url_map.iter_rules()]))

# =============================
# Utils
# =============================

def tokenize(text: str, lang: str):
    if lang in ["ko", "en"]:
        return text.split()
    # ì¼ë³¸ì–´/ì¤‘êµ­ì–´ëŠ” ê³µë°± ê¸°ì¤€ + ê¸€ì ë‹¨ìœ„ fallback
    return list(text)


def bad_request(msg: str):
    return jsonify({"ok": False, "error": {"code": "BAD_REQUEST", "message": msg}}), 400

def extract_video_id(url: str):
    if not url:
        return None
    m = re.search(r"[?&]v=([A-Za-z0-9_-]{11})", url)
    if m: return m.group(1)
    m = re.search(r"youtu\.be/([A-Za-z0-9_-]{11})", url)
    if m: return m.group(1)
    m = re.search(r"shorts/([A-Za-z0-9_-]{11})", url)
    if m: return m.group(1)
    m = re.search(r"embed/([A-Za-z0-9_-]{11})", url)
    if m: return m.group(1)
    return None

RE_KO = re.compile(r"[ê°€-í£]")
RE_JA = re.compile(r"[\u3040-\u309F\u30A0-\u30FF]")
RE_ZH = re.compile(r"[\u4E00-\u9FFF]")
RE_EN = re.compile(r"[A-Za-z]")
LAUGH_TOKENS = [ "ã…‹ã…‹ã…‹", "ã…ã…", "ã…ã…ã…", "lol", "lmao", "www"]


def detect_lang_auto(text: str) -> str:
    if not text:
        return "en"
    if RE_KO.search(text): return "ko"
    if RE_JA.search(text): return "ja"
    zh_hits = len(RE_ZH.findall(text))
    en_hits = len(RE_EN.findall(text))
    if zh_hits >= 2 and en_hits == 0: return "zh"
    if en_hits > 0: return "en"
    return "en"

def preprocess(text: str, lang: str) -> str:
    t = (text or "").strip().lower()
    if lang == "en":
        t = re.sub(r"[^a-z0-9\s]", " ", t)
    elif lang == "ko":
        t = re.sub(r"[^0-9a-zê°€-í£\s]", " ", t)
    else:  # ja/zh
        t = re.sub(r"[^\w\u3040-\u30FF\u4E00-\u9FFF\s]", " ", t)
    t = re.sub(r"\s+", " ", t).strip()
    return t

def score_keywords(cleaned: str, keywords: list) -> int:
    return sum(1 for kw in keywords if kw and kw in cleaned)

def match_keywords(cleaned: str, keywords: list, lang: str):
    tokens = tokenize(cleaned, lang)
    matched = []

    for kw in keywords:
        if len(kw) < 2:   # ğŸ”¥ í•œ ê¸€ì í‚¤ì›Œë“œ ì°¨ë‹¨
            continue

        if lang in ["ko", "en"]:
            if kw in tokens:
                matched.append(kw)
        else:
            # ì¼ë³¸ì–´/ì¤‘êµ­ì–´ëŠ” substring í—ˆìš© but ê¸¸ì´ 2 ì´ìƒë§Œ
            if kw in cleaned:
                matched.append(kw)
    if lang == "ko":
        # í† í° ì•ˆì— í‚¤ì›Œë“œ í¬í•¨ í—ˆìš© (ë‹¨, kw ê¸¸ì´ 2 ì´ìƒì€ ì´ë¯¸ í•„í„°ë¨)
        if any(kw in tok for tok in tokens):
            matched.append(kw)
    elif lang == "en":
        if kw in tokens:
            matched.append(kw)

    return matched

def classify_sentiment(text: str, lang_choice: str):
    lang = detect_lang_auto(text) if lang_choice == "auto" else lang_choice
    cleaned = preprocess(text, lang)

    if len(cleaned) < MIN_LEN:
        return "neutral", lang, [], []

    pos_list, neg_list = KEYWORDS.get(lang, KEYWORDS["en"])

    pos_matched = match_keywords(cleaned, pos_list, lang)
    neg_matched = match_keywords(cleaned, neg_list, lang)

    pos = len(pos_matched)
    neg = len(neg_matched) *3

    # ì´ëª¨ì§€ ë³´ì •
    for e in POSITIVE_EMOJIS:
        if e in text:
            pos += 1
            pos_matched.append(e)

    for e in NEGATIVE_EMOJIS:
        if e in text:
            neg += 1
            neg_matched.append(e)

        # ì›ƒìŒ ë³´ì • (í•œ ë²ˆë§Œ)
    if any(l in text.lower() for l in LAUGH_TOKENS):
        pos += 1
        pos_matched.append("laugh")

    # threshold
    # âœ… í•œìª½ë§Œ ì ìˆ˜ê°€ ìˆìœ¼ë©´ ê·¸ìª½ìœ¼ë¡œ
    if pos > 0 and neg == 0:
        return "positive", lang, pos_matched, neg_matched
    if neg > 0 and pos == 0:
        return "negative", lang, pos_matched, neg_matched

    # âœ… ë‘˜ ë‹¤ ìˆì„ ë•Œë§Œ ì• ë§¤í•˜ë©´ neutral
    if abs(pos - neg) <= 1:
        return "neutral", lang, pos_matched, neg_matched

    return "neutral", lang, pos_matched, neg_matched

def build_summary(ratios: dict) -> str:
    p = ratios.get("positive", 0.0)
    n = ratios.get("negative", 0.0)
    u = ratios.get("neutral", 0.0)
    top = max(p, n, u)
    close = sum(1 for x in (p, n, u) if abs(top - x) <= 0.10)
    if close >= 2: return "ë°˜ì‘ì´ ì—‡ê°ˆë¦¬ëŠ” ì˜ìƒì…ë‹ˆë‹¤."
    if top == p: return "ì „ë°˜ì ìœ¼ë¡œ ë°˜ì‘ì´ ì¢‹ì€ ì˜ìƒì…ë‹ˆë‹¤."
    if top == n: return "ë¶€ì •ì ì¸ ë°˜ì‘ì´ ë§ì€ ì˜ìƒì…ë‹ˆë‹¤."
    return "ì¤‘ë¦½ì ì¸ ë°˜ì‘ì´ ë§ì€ ì˜ìƒì…ë‹ˆë‹¤."

def fetch_youtube_comments(video_id: str, max_comments: int, sort: str):
    if not YOUTUBE_API_KEY:
        raise RuntimeError("Missing YOUTUBE_API_KEY in .env")

    order_param = "time" if sort == "latest" else "relevance"

    comments = []
    page_token = None

    while len(comments) < max_comments:
        remaining = max_comments - len(comments)
        max_results = 100 if remaining > 100 else remaining

        params = {
            "part": "snippet",
            "videoId": video_id,
            "maxResults": max_results,
            "order": order_param,
            "textFormat": "plainText",
            "key": YOUTUBE_API_KEY,
        }

        if page_token:
            params["pageToken"] = page_token

        r = requests.get(
            "https://www.googleapis.com/youtube/v3/commentThreads",
            params=params,
            timeout=15
        )

        print("DEBUG STATUS:", r.status_code)

        if r.status_code != 200:
            print("DEBUG RESPONSE:", r.text)
            raise RuntimeError(f"YouTube API error: {r.status_code} {r.text}")

        data = r.json()
        items = data.get("items", [])

        for it in items:
            sn = it["snippet"]["topLevelComment"]["snippet"]
            comments.append({
                "text": sn.get("textDisplay") or "",
                "likeCount": int(sn.get("likeCount") or 0),
                "publishedAt": sn.get("publishedAt") or "",
                "author": sn.get("authorDisplayName") or ""
            })

        page_token = data.get("nextPageToken")
        if not page_token or not items:
            break

    return comments

# =============================
# API
# =============================

@app.post("/api/analyze")


def api_analyze():
    print("DEBUG KEY:", YOUTUBE_API_KEY)

    try:
        data = request.get_json(force=True) or {}

        url = (data.get("url") or "").strip()
        max_comments = data.get("maxComments")
        sort = data.get("sort", "latest")
        lang = data.get("lang", "auto")
        random_sample = bool(data.get("randomSample", False))

        if not url:
            return bad_request("url is required")
        try:
            max_comments = int(max_comments)
        except:
            return bad_request("maxComments must be number")

        if max_comments not in ALLOWED_MAX:
            return bad_request("maxComments must be one of 50, 100, 200")
        if sort not in ALLOWED_SORT:
            return bad_request('sort must be "latest" or "likes"')
        if lang not in ALLOWED_LANG:
            return bad_request('lang must be "auto"|"ko"|"en"|"ja"|"zh"')

        video_id = extract_video_id(url)
        if not video_id:
            return bad_request("Could not extract videoId from url")
        print("DEBUG video_id:", video_id)

        raw_comments = fetch_youtube_comments(video_id, max_comments, sort)

        if random_sample:
            random.shuffle(raw_comments)

        if len(raw_comments) == 0:
            return jsonify({
                "ok": True,
                "meta": {"videoId": video_id},
                "counts": {"totalFetched": 0},
                "sentiment": {"positive": 0, "negative": 0, "neutral": 0},
                "ratios": {"positive": 0.0, "negative": 0.0, "neutral": 0.0},
                "summary": "ëŒ“ê¸€ì´ ì—†ì–´ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "comments": []
            })

        stats = {"positive": 0, "negative": 0, "neutral": 0}
        labeled = []

        for c in raw_comments:
            text = c.get("text", "")
            sent, detected_lang, pos_m, neg_m = classify_sentiment(text, lang)

            stats[sent] += 1
            labeled.append({
                "text": text,
                "sentiment": sent,
                "lang": detected_lang,
                "likeCount": c.get("likeCount", 0),
                "publishedAt": c.get("publishedAt", ""),
                "author": c.get("author", ""),
                "reason": {
                    "positive": pos_m,
                    "negative": neg_m
                }
            })

        total = len(labeled)
        ratios = {
            "positive": round(stats["positive"] / total, 4),
            "negative": round(stats["negative"] / total, 4),
            "neutral": round(stats["neutral"] / total, 4),
        }

        return jsonify({
            "ok": True,
            "meta": {
                "videoId": video_id,
                "requested": {"maxComments": max_comments, "sort": sort, "lang": lang, "randomSample": random_sample},
                "youtubeOrder": "time" if sort == "latest" else "relevance"
            },
            "counts": {"totalFetched": total},
            "sentiment": stats,
            "ratios": ratios,
            "summary": build_summary(ratios),
            "comments": labeled
        })

    except Exception as e:
        import traceback
        traceback.print_exc()  # âœ… í„°ë¯¸ë„ì— ë¹¨ê°„ traceback ì¶œë ¥
        return jsonify({
            "ok": False,
            "error": {"code": "INTERNAL_ERROR", "message": str(e)}
        }), 500

@app.post("/api/suggest")
def api_suggest():
    try:
        data = request.get_json(force=True) or {}

        text = (data.get("text") or "").strip()
        label = data.get("label")

        if not text:
            return bad_request("text is required")

        if label not in {"positive", "negative", "neutral"}:
            return bad_request("label must be positive/negative/neutral")

        suggestion = {
            "text": text,
            "label": label,
            "status": "pending",   # í•­ìƒ ê²€í†  ëŒ€ê¸°
            "createdAt": datetime.utcnow().isoformat()
        }

        with open("suggestions.jsonl", "a", encoding="utf-8") as f:
            f.write(json.dumps(suggestion, ensure_ascii=False) + "\n")

        return jsonify({"ok": True, "message": "Suggestion saved (pending review)"})

    except Exception as e:
        return jsonify({
            "ok": False,
            "error": {"code": "INTERNAL_ERROR", "message": str(e)}
        }), 500


if __name__ == "__main__":
    app.run(debug=True)

